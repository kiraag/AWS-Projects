
1. Create a public S3 bucket named `devops-public-13065`. Ensure that the bucket allows public access to its objects.

2. Create a private S3 bucket named `devops-private-29867`. Ensure that the bucket does not allow public access.

3. Create a Lambda function named `devops-copyfunction`. This function should be triggered by uploads to the public S3 bucket and should copy the uploaded file to the private bucket. Create the necessary policies and a role named `lambda_execution_role`. Attach these policies to the role, and then link this role to the Lambda function.

4. `lambda-function.py` is already present at the file of `lambda-function.py`, replace REPLACE-WITH-YOUR-DYNAMODB-TABLE and REPLACE-WITH-YOUR-PRIVATE-BUCKET values.

5. Create a DynamoDB table named `devops-S3CopyLogs` with a partition key `LogID` (string). This table will store logs generated by the Lambda function, including details such as source bucket name, destination bucket name, and object key.

6. For testing upload the sample file to the public S3 bucket. The Lambda function should trigger and copy the file to the private bucket.

7. Verify that the file has been successfully copied to the private bucket by checking the private bucket in the S3 console.

8. Verify that a log entry has been created in the DynamoDB table containing the file copy details.

```
* Note: Attach the following managed policies to the role:

- AmazonS3FullAccess: To access S3 buckets.
- AmazonDynamoDBFullAccess: To log operations in DynamoDB.
- AWSLambdaBasicExecutionRole: For logging to CloudWatch.


This project is incredibly useful for organizations that need a seamless, secure, and automated way to manage file transfers in the cloud. By using a public S3 bucket for uploads and a private bucket for secure storage, it ensures sensitive files are safeguarded. The integration with DynamoDB provides detailed logs for tracking and auditing, which is crucial for compliance and security monitoring. This approach not only improves operational efficiency but also eliminates manual intervention, reducing the risk of errors and enhancing data governance. It's a scalable and cost-effective solution for secure file management workflows.
